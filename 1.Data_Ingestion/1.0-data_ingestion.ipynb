{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee63c3da",
   "metadata": {},
   "source": [
    "### ğŸ¯ Module Overview\n",
    "This module covers everything you need to know about parsing and ingesting data for RAG systems, from basic text files to complex PDFs and databases. We'll use LangChain v0.3 and explore each technique with practical examples.\n",
    "\n",
    "Table of Contents\n",
    "\n",
    "- Introduction to Data Ingestion\n",
    "- Text Files (.txt)\n",
    "- PDF Documents\n",
    "- Microsoft Word Documents\n",
    "- CSV and Excel Files\n",
    "- JSON and Structured Data\n",
    "- Web Scraping\n",
    "- Databases (SQL)\n",
    "- Audio and Video Transcripts\n",
    "- Advanced Techniques\n",
    "- Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d21f7",
   "metadata": {},
   "source": [
    "## Introduction to Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef102702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All necessary libraries imported successfully!\n",
      "Document Example:\n",
      "Content: This is the main text content that will be embedded and searched.\n",
      "Metadata: {'source': 'example.txt', 'page': 1, 'author': 'Apoorv', 'date_created': '2025-11-1', 'custom_info': 'Additional metadata can go here'}\n",
      "Metadata is crucial for:\n",
      "â¡ï¸ Filtering and searching results\n",
      "â¡ï¸ Tracking document sources\n",
      "â¡ï¸ Providing context in responses\n",
      "â¡ï¸ Debugging and auditing\n",
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "#ğŸ”§ Step 2: Import Required Libraries\n",
    "from typing import List, Dict, Any\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#ğŸ“¥ Step 3: Import LangChain's Document Class\n",
    "from langchain_core.documents import Document\n",
    "# â¡ï¸ We'll use this class to convert raw text into a document format\n",
    "\n",
    "#âœ‚ï¸ Step 4: Import Text Splitters (We'll Use Later)\n",
    "from langchain_text_splitters import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter\n",
    ")\n",
    "print(\"All necessary libraries imported successfully!\")\n",
    "# c:\\Users\\sahus\\OneDrive\\Desktop\\RAG_Bootcamp\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "#   from .autonotebook import tqdm as notebook_tqdm\n",
    "# All necessary libraries imported successfully!\n",
    "\n",
    "#âœ‚ï¸ These will help us split large documents into smaller chunks later.\n",
    "\n",
    "# ğŸ§± Step 6: Understand the Document Structure\n",
    "# ğŸ“„ Create a Simple Document Example\n",
    "doc = Document(\n",
    "    page_content=\"This is the main text content that will be embedded and searched.\",\n",
    "    metadata={\n",
    "        \"source\": \"example.txt\",\n",
    "        \"page\": 1,\n",
    "        \"author\": \"Apoorv\",\n",
    "        \"date_created\": \"2025-11-1\",\n",
    "        \"custom_info\": \"Additional metadata can go here\"\n",
    "    }\n",
    ")\n",
    "# ğŸ“ Explanation:\n",
    "# â€¢\tpage_content: Actual data/content\n",
    "# â€¢\tmetadata: Info about the data source\n",
    "# ğŸ“ You can replace these with your own values!\n",
    "\n",
    "# ğŸ” Step 7: Print the Document Content and Metadata\n",
    "print(\"Document Example:\")\n",
    "print(f\"Content: {doc.page_content}\")\n",
    "print(f\"Metadata: {doc.metadata}\")\n",
    "# Document Example:\n",
    "# Content: This is the main text content that will be embedded and searched.\n",
    "# Metadata: {'source': 'example.txt', 'page': 1, 'author': 'Apoorv', 'date_created': '2025-11-1', 'custom_info': 'Additional metadata can go here'}\n",
    "\n",
    "#ğŸ’¡ Why Metadata Matters?\n",
    "print(\"Metadata is crucial for:\")\n",
    "print(\"â¡ï¸ Filtering and searching results\")\n",
    "print(\"â¡ï¸ Tracking document sources\")\n",
    "print(\"â¡ï¸ Providing context in responses\")\n",
    "print(\"â¡ï¸ Debugging and auditing\")\n",
    "# âœ… Example Use Case:\n",
    "# If user asks â€œWho is the author?â€, we can retrieve that from the metadata.\n",
    "# ğŸ§ª Bonus: Check Document Type\n",
    "print(type(doc))\n",
    "\n",
    "# Metadata is crucial for:\n",
    "# â¡ï¸ Filtering and searching results\n",
    "# â¡ï¸ Tracking document sources\n",
    "# â¡ï¸ Providing context in responses\n",
    "# â¡ï¸ Debugging and auditing\n",
    "# <class 'langchain_core.documents.base.Document'>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2bfca",
   "metadata": {},
   "source": [
    "### Text Files (.txt) - The Simplest Case {#2-text-files}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2757dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sample text files created!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ§ª Step-by-Step: Reading a Simple .txt File\n",
    "# ğŸ—‚ï¸ Step 1: Create Folder and File\n",
    "import os\n",
    "\n",
    "# ğŸ“ Create folders if they don't exist\n",
    "os.makedirs(\"data/text_files\", exist_ok=True)\n",
    "# âœ… This will create a folder data/text_files/\n",
    "# âœ… exist_ok=True means: don't throw error if folder already exists\n",
    "\n",
    "#ğŸ“ Step 2: Create Sample Text Files with Python\n",
    "sample_texts={\n",
    "    \"data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "    \"data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "# ğŸ§  This dictionary has:\n",
    "# â€¢\tğŸ“ File path as key\n",
    "# â€¢\tğŸ“„ Text content as value\n",
    "\n",
    "# âœï¸ Step 3: Write Text into the Files\n",
    "for filepath,content in sample_texts.items():\n",
    "    with open(filepath,'w',encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"âœ… Sample text files created!\")\n",
    "# âœ… Sample text files created!\n",
    "\n",
    "# â¡ï¸ This loop will:\n",
    "# â€¢\tCreate the text files\n",
    "# â€¢\tWrite content into them\n",
    "# â€¢\tUse UTF-8 encoding to avoid any text issues\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed73ef",
   "metadata": {},
   "source": [
    "### TextLoader- Read Single File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e624aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Loaded 1 document(s)\n",
      "ğŸ” Content Preview: Python Programming Introduction\n",
      "\n",
      "Python is a high-level, interpreted programming language known for \n",
      "ğŸ—‚ï¸ Metadata: {'source': 'data/text_files/python_intro.txt'}\n",
      "[Document(metadata={'source': 'data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
     ]
    }
   ],
   "source": [
    "#ğŸ“– Step 4: Read Text File Using TextLoader\n",
    "#ğŸ”Œ Import TextLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "#âœ… You can also use from langchain.document_loaders, but both work\n",
    "#âœ… Use the one thatâ€™s not deprecated\n",
    "\n",
    "# ğŸ“¥ Step 5: Load One File \n",
    "loader = TextLoader(\"data/text_files/python_intro.txt\", encoding=\"utf-8\")\n",
    "# ğŸ” Step 6: Convert to Documents\n",
    "doc1 = loader.load()\n",
    "# ğŸ–¨ï¸ Step 7: Print and Preview Document\n",
    "print(f\"ğŸ“„ Loaded {len(doc1)} document(s)\")\n",
    "print(\"ğŸ” Content Preview:\", doc1[0].page_content[:100])\n",
    "print(\"ğŸ—‚ï¸ Metadata:\", doc1[0].metadata)\n",
    "# ğŸ“„ Loaded 1 document(s)\n",
    "# ğŸ” Content Preview: Python Programming Introduction\n",
    "\n",
    "# Python is a high-level, interpreted programming language known for \n",
    "# ğŸ—‚ï¸ Metadata: {'source': 'data/text_files/python_intro.txt'}\n",
    "\n",
    "print(doc1)\n",
    "# [Document(metadata={'source': 'data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n",
    "#â¡ï¸ This loads the .txt file\n",
    "#â¡ï¸ UTF-8 ensures it reads special characters correctly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a15baf8",
   "metadata": {},
   "source": [
    "### DirectoryLoader- Multiple Text Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23f86643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 596.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Total Documents Loaded: 2\n",
      "\n",
      "ğŸ“„ Document 1\n",
      "ğŸ“ Source: data\\text_files\\machine_learning.txt\n",
      "ğŸ§¾ Content Length: 575 characters\n",
      "\n",
      "ğŸ“„ Document 2\n",
      "ğŸ“ Source: data\\text_files\\python_intro.txt\n",
      "ğŸ§¾ Content Length: 489 characters\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”Œ Step 8: Import DirectoryLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "# ğŸ“ Step 9: Setup Directory Loader\n",
    "directory_loader = DirectoryLoader(\n",
    "    path=\"data/text_files\",\n",
    "    glob=\"**/*.txt\",  # ğŸ” Look for all `.txt` files recursively\n",
    "    loader_cls=TextLoader,  # ğŸ“˜ Use TextLoader for each file\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"},\n",
    "    show_progress=True\n",
    ")\n",
    "# ğŸ“Œ Explanation:\n",
    "# â€¢\tpath: directory where files are stored\n",
    "# â€¢\tglob: pattern to match all .txt files\n",
    "# â€¢\tloader_cls: which loader to use (TextLoader here)\n",
    "# â€¢\tloader_kwargs: any extra config like encoding\n",
    "# â€¢\tshow_progress: show progress bar while loading\n",
    "\n",
    "# ğŸ“¥ Step 10: Load All Documents from Directory\n",
    "documents = directory_loader.load()\n",
    "\n",
    "# ğŸ“¤ Step 11: Print Summary of Loaded Documents\n",
    "print(f\"ğŸ“„ Total Documents Loaded: {len(documents)}\\n\")\n",
    "\n",
    "for i, doc in enumerate(documents):\n",
    "    print(f\"ğŸ“„ Document {i+1}\")\n",
    "    print(f\"ğŸ“ Source: {doc.metadata['source']}\")\n",
    "    print(f\"ğŸ§¾ Content Length: {len(doc.page_content)} characters\\n\")\n",
    "\n",
    "# Output:\n",
    "# 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 279.57it/s]ğŸ“„ Total Documents Loaded: 2\n",
    "\n",
    "# ğŸ“„ Document 1\n",
    "# ğŸ“ Source: data\\text_files\\machine_learning.txt\n",
    "# ğŸ§¾ Content Length: 575 characters\n",
    "\n",
    "# ğŸ“„ Document 2\n",
    "# ğŸ“ Source: data\\text_files\\python_intro.txt\n",
    "# ğŸ§¾ Content Length: 489 characters\n",
    "\n",
    "# | âœ… **Advantages**                                         | âŒ **Disadvantages**                                  |\n",
    "# | -------------------------------------------------------- | ---------------------------------------------------- |\n",
    "# | ğŸ”„ **Loads multiple files at once**                      | âš ï¸ **All files must be of same type (e.g., .txt)**   |\n",
    "# | ğŸ§  **Supports glob patterns for flexible file matching** | âŒ **Limited error handling for bad files**           |\n",
    "# | ğŸ“Š **Can show progress**                                 | ğŸ˜ **Can be memory intensive for large directories** |\n",
    "# | ğŸ“ **Scans subfolders too (recursive)**                  |                                                      |\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374239e7",
   "metadata": {},
   "source": [
    "### Text Splitting Methods in Langchain\n",
    "1.\tCharacter-based Text Splitter\n",
    "2.\tRecursive Character-based Text Splitter\n",
    "3.\tToken-based Text Splitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c1dab4",
   "metadata": {},
   "source": [
    "### 1. Character-based Text Splitter\n",
    "â€¢\tHow It Works: Splits text based on a fixed number of characters.\n",
    "\n",
    "o\tYou define the chunk size and overlap (if any).\n",
    "\n",
    "o\tIt's simple and works well when you want to split text into small fixed-length parts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b3c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'data\\\\text_files\\\\machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '), Document(metadata={'source': 'data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n",
      "Number of Chunks: 4\n",
      "First Chunk: Machine Learning Basics\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
      "chunks ['Machine Learning Basics\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve', 'from experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\nTypes of Machine Learning:', '1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties', 'Applications include image recognition, speech processing, and recommendation systems']\n"
     ]
    }
   ],
   "source": [
    "### Different text splitting strategies\n",
    "from langchain_text_splitters import (\n",
    "    CharacterTextSplitter,\n",
    " \n",
    ")\n",
    "print(documents)\n",
    "# [Document(metadata={'source': 'data\\\\text_files\\\\machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '), Document(metadata={'source': 'data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n",
    "text = documents[0].page_content\n",
    "text\n",
    "# 'Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '\n",
    "\n",
    "# Use the character-based splitter\n",
    "splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=200, chunk_overlap=20,length_function=len)\n",
    "# Split the document into chunks\n",
    "chunks = splitter.split_text(text)\n",
    "\n",
    "# Output the chunks\n",
    "print(\"Number of Chunks:\", len(chunks)) # Number of Chunks: 4\n",
    "print(\"First Chunk:\", chunks[0]) # First Chunk: Machine Learning Basics\n",
    "# Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "print(\"chunks\",chunks) # chunks ['Machine Learning Basics\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve', 'from experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\nTypes of Machine Learning:', '1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties', 'Applications include image recognition, speech processing, and recommendation systems']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b24101",
   "metadata": {},
   "source": [
    "### 2. Recursive Character-based Text Splitter\n",
    "â€¢\tHow It Works: Tries to split text multiple times using different separators (e.g., new lines, double spaces) until the chunk size is reached.\n",
    "\n",
    "o\tIt's recommended because it respects the text structure and adapts based on the content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b58b2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 4 chunks\n",
      "First chunk: Machine Learning Basics\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables system...\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\" \"],  # Try these separators in order\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=20,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "recursive_chunks = recursive_splitter.split_text(text)\n",
    "print(f\"Created {len(recursive_chunks)} chunks\")\n",
    "print(f\"First chunk: {recursive_chunks[0][:100]}...\")\n",
    "\n",
    "# Created 4 chunks\n",
    "# First chunk: Machine Learning Basics \n",
    "# Machine learning is a subset of artificial intelligence that enables system...\n",
    "\n",
    "print(recursive_chunks[0])\n",
    "print(\"-----------------\")\n",
    "print(recursive_chunks[1])\n",
    "print(\"------------------\")\n",
    "print(recursive_chunks[2])\n",
    "# Machine Learning Basics\n",
    "\n",
    "# Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "# from experience without being explicitly programmed. It focuses on developing\n",
    "# -----------------\n",
    "# on developing computer programs\n",
    "# that can access data and use it to learn for themselves.\n",
    "\n",
    "# Types of Machine Learning:\n",
    "# 1. Supervised Learning: Learning with labeled data\n",
    "# 2. Unsupervised Learning:\n",
    "# ------------------\n",
    "# Learning: Finding patterns in unlabeled data\n",
    "# 3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "# Applications include image recognition, speech processing, and recommendation\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf47267b",
   "metadata": {},
   "source": [
    "### 3. Token-based Text Splitter\n",
    "â€¢\tHow It Works: Splits the text into tokens, considering spaces as separators.\n",
    "\n",
    "o\tIt focuses on words and spaces instead of just characters, making it more suitable for token-based models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeda59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Token Chunks: 3\n",
      "First Token Chunk: Machine Learning Basics\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
      "from experience without being explicitly programmed. It focuses on developing computer programs\n",
      "that can access data and use it to learn for themselves.\n",
      "\n",
      "Types\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "# Use the token-based splitter\n",
    "token_splitter = TokenTextSplitter(chunk_size=50, chunk_overlap=10)\n",
    "\n",
    "# Split the document into tokens\n",
    "token_chunks = token_splitter.split_text(text)\n",
    "\n",
    "# Output the token chunks\n",
    "print(\"Number of Token Chunks:\", len(token_chunks)) \n",
    "print(\"First Token Chunk:\", token_chunks[0])\n",
    "\n",
    "# Number of Token Chunks: 3\n",
    "# First Token Chunk: Machine Learning Basics\n",
    "\n",
    "# Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "# from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "# that can access data and use it to learn for themselves.\n",
    "\n",
    "# Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ebe2a9",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    " â€¢\tText splitting is crucial for making sure that documents fit within the context window of models.\n",
    "\n",
    "â€¢\tCharacter-based splitting is simple and works when the document has clear delimiters (e.g., new lines).\n",
    "\n",
    "â€¢\tRecursive character-based splitting is better for general use, as it tries multiple separators and respects the structure of the document.\n",
    "\n",
    "â€¢\tToken-based splitting is used when working with models that are limited by token count, like GPT.\n",
    "\n",
    "â€¢\tThe chunk overlap feature is helpful to maintain context between adjacent chunks, ensuring that important information isnâ€™t lost when splitting text.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_Bootcamp (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
